{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Labeling alerts based on existing tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os.path\n",
    "import copy\n",
    "import pickle\n",
    "import pandas\n",
    "import numpy\n",
    "import numpy.random\n",
    "\n",
    "# Old-fashioned learning\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "\n",
    "# Deep learning\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from intensix.monitor.models import Alert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATA = \"../data\"\n",
    "MODELS = \"../models\"\n",
    "\n",
    "STAY_TAGS = os.path.join(DATA, \"stay_tags.pkl\")\n",
    "SOMESTAYS = os.path.join(DATA, \"stays-3-14-days\")\n",
    "\n",
    "with open(STAY_TAGS, \"rb\") as f:\n",
    "    stay_tags = pickle.load(f)\n",
    "    \n",
    "with open(SOMESTAYS, \"r\") as f:\n",
    "    somestays = []\n",
    "    for line in f:\n",
    "        somestays.append(line.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function for labeling a single stay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def label_alerts(stayid, df, alerts):\n",
    "    \"\"\"Adds tag-based labels.\n",
    "    \"\"\"\n",
    "    alerts = numpy.append(alerts, numpy.zeros_like(alerts[:, -1:]), axis=1)\n",
    "    if stayid in stay_tags:\n",
    "        tags = sorted(\n",
    "            set([(pandas.to_datetime(tag['time']) - df.index[0]).total_seconds()//60 \n",
    "                 for tag in stay_tags[stayid]\n",
    "                 if 'deterioration' in tag['concept']]))\n",
    "        ia = 0\n",
    "        it = 0\n",
    "        while True:\n",
    "            if it == len(tags):\n",
    "                break\n",
    "            if ia == len(alerts):\n",
    "                break\n",
    "            if alerts[ia, 0] > tags[it]:\n",
    "                it += 1\n",
    "                continue\n",
    "            alerts[ia, -1] = 1\n",
    "            ia += 1\n",
    "    return alerts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loop over the dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "POS = 0\n",
    "TOT = 0\n",
    "dataset = []\n",
    "for stayid in somestays:\n",
    "    try:\n",
    "        with open(os.path.join(DATA, \"monitor-dataset-{}.pkl\".format(stayid)),\n",
    "                  \"rb\") as f:\n",
    "            df = pickle.load(f)\n",
    "        with open(os.path.join(DATA, \"monitor-dataset-{}-alerts.npy\".format(stayid)),\n",
    "                  \"rb\") as f:\n",
    "            alerts = numpy.load(f)\n",
    "        print(\"+\", end=\"\")\n",
    "        labeled_alerts = label_alerts(stayid, df, alerts)\n",
    "        numpy.save(os.path.join(DATA, \"monitor-dataset-{}-labeled-alerts.npy\".format(stayid)),\n",
    "                   labeled_alerts)\n",
    "        dataset.append(labeled_alerts)\n",
    "        POS += int(numpy.sum(labeled_alerts[:, -1]))\n",
    "        TOT += len(labeled_alerts)\n",
    "    except FileNotFoundError:\n",
    "        print(\"-\", end=\"\")\n",
    "print()\n",
    "print(\"{} positive alerts out of {} total ({:.2f})\".format(POS, TOT, POS/TOT))\n",
    "dataset = numpy.concatenate(dataset, axis=0)\n",
    "numpy.save(os.path.join(DATA, \"labeled-alerts.npy\"), dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline tests --- scikit-learn style classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CV = 5\n",
    "TF = 1 / CV\n",
    "class_weight = {0: POS,\n",
    "                1: TOT - POS}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(class_weight=class_weight)\n",
    "scores = cross_val_score(model, dataset[:, 2:-1], dataset[:, -1], cv=CV, scoring='f1')\n",
    "print(scores.mean(), scores.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ntrain = int((1 - TF) * len(dataset))\n",
    "trainset = dataset[:ntrain]\n",
    "testset = dataset[ntrain:]\n",
    "model.fit(trainset[:, 2:-1], trainset[:, -1])\n",
    "print(\"TRAIN:\\n{}\".format(confusion_matrix(trainset[:, -1], model.predict(trainset[:, 2:-1])) /\n",
    "                          len(trainset)))\n",
    "print(\"\\nTEST:\\n{}\".format(confusion_matrix(testset[:, -1], model.predict(testset[:, 2:-1])) /\n",
    "                           len(testset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear SVM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = SGDClassifier(class_weight=class_weight, tol=0.001)\n",
    "scores = cross_val_score(model, dataset[:, 2:-1], dataset[:, -1], cv=CV, scoring='f1')\n",
    "print(scores.mean(), scores.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ntrain = int((1 - TF) * len(dataset))\n",
    "trainset = dataset[:ntrain]\n",
    "testset = dataset[ntrain:]\n",
    "model.fit(trainset[:, 2:-1], trainset[:, -1])\n",
    "print(\"TRAIN:\\n{}\".format(confusion_matrix(trainset[:, -1], model.predict(trainset[:, 2:-1])) / \n",
    "                          len(trainset)))\n",
    "print(\"\\nTEST:\\n{}\".format(confusion_matrix(testset[:, -1], model.predict(testset[:, 2:-1])) /\n",
    "                          len(testset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NEPOCHS = 100\n",
    "BATCH_SIZE = 16\n",
    "LEARNING_RATE = 0.0001\n",
    "\n",
    "model = Alert(hidden_size=128, p=0.5)\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "ntrain = int((1 - TF) * len(dataset))\n",
    "trainset = torch.from_numpy(dataset[:ntrain])\n",
    "testset = torch.from_numpy(dataset[ntrain:])\n",
    "\n",
    "def truepred(model, dset):\n",
    "    \"\"\"Returns true and predicted labels.\n",
    "    \"\"\"\n",
    "    y_true = dset[:, -1].numpy()\n",
    "    y_pred = numpy.round(model(Variable(dset[:, 2:-1]))\n",
    "                         .data.numpy()[:, 0])\n",
    "    return y_true, y_pred\n",
    "    \n",
    "train_loader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "iepoch = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "iepoch0 = iepoch\n",
    "while iepoch != iepoch0 + NEPOCHS:\n",
    "    model.train()\n",
    "    train_loss = 0.\n",
    "    train_samples = 0\n",
    "    print(\"batch\", end=\" \")\n",
    "    for ibatch, batch in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        z = model(Variable(batch[:, 2:-1]))\n",
    "        y = Variable(batch[:, -1]).resize(batch.size(0), 1)\n",
    "        weight = (y * class_weight[1] + (1 - y) * class_weight[0])/(class_weight[0] + class_weight[1])\n",
    "        loss = F.binary_cross_entropy(z, y, weight)\n",
    "        loss.backward()\n",
    "        train_loss += loss.data[0] * batch.size(0)\n",
    "        train_samples += batch.size(0)\n",
    "        optimizer.step()\n",
    "        if (ibatch + 1) % (len(trainset) // BATCH_SIZE // 5) == 0:\n",
    "            print(\"{}({}): {:.4f}\".format(ibatch + 1, iepoch + 1, train_loss / train_samples), end=\" \")\n",
    "    print()\n",
    "    train_loss /= train_samples\n",
    "        \n",
    "    model.eval()\n",
    "    z = model(Variable(testset[:, 2:-1]))\n",
    "    y = Variable(testset[:, -1]).resize(len(testset), 1)\n",
    "    weight = (y * class_weight[1] + (1 - y) * class_weight[0])/(class_weight[0] + class_weight[1])\n",
    "    loss = F.binary_cross_entropy(z, y, weight)\n",
    "    print(\"EPOCH {}: train loss: {:.4f}, test loss: {:.4f}\".format(iepoch + 1, train_loss, loss.data[0]))  \n",
    "    iepoch += 1\n",
    "    \n",
    "    if iepoch % 10 == 0:\n",
    "        train_true, train_pred = truepred(model, trainset)\n",
    "        test_true, test_pred = truepred(model, testset)\n",
    "\n",
    "        print(\"\\nTRAIN:\\n{}\\nF1 = {:.4f}\\n\\nTEST:\\n{}\\nF1 = {:.4f}\\n\"\n",
    "              .format(confusion_matrix(train_true, train_pred)/len(trainset),\n",
    "                      f1_score(train_true, train_pred),\n",
    "                      confusion_matrix(test_true, test_pred)/len(testset), \n",
    "                      f1_score(test_true, test_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), os.path.join(MODELS, \"alerts.model\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
